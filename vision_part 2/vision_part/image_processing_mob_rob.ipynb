{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Aj28E4takcMS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /Users/lucas/opt/anaconda3/lib/python3.8/site-packages (0.5.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhKhUm5TSl1l"
   },
   "source": [
    "### Ball XY Coordinate Detection using Color Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1638483287685,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "6DkXI8JU_F5X"
   },
   "outputs": [],
   "source": [
    "def color_filter(image,color):\n",
    "    '''\n",
    "    Function used to performed color filtering\n",
    "    image: The input image on which color filtering is performed\n",
    "    color: The name of the color which we want to filter\n",
    "    '''\n",
    "    #Get a copy of the input image\n",
    "    result = image.copy()\n",
    "\n",
    "    #Convert image in HSV color space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #Form a mask to filter Red in HSV space\n",
    "    if color==\"red\":\n",
    "        lower1 = np.array([0, 30, 0])\n",
    "        upper1 = np.array([8, 255,205])\n",
    "        lower2 = np.array([170,30,0])\n",
    "        upper2 = np.array([179,255,205])\n",
    "        lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "        upper_mask = cv2.inRange(image, lower2, upper2)\n",
    "        mask = lower_mask + upper_mask;\n",
    "\n",
    "    #Form a mask to filter green in HSV space\n",
    "    elif color==\"green\":\n",
    "        lower1 = np.array([75, 30, 20])\n",
    "        upper1 = np.array([90, 225, 225])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "\n",
    "    #Form a mask to filter Yellow in HSV space\n",
    "    elif color==\"yellow\":\n",
    "        lower1 = np.array([10, 0, 0])\n",
    "        upper1 = np.array([32, 255, 255])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "\n",
    "    #Form a mask to filter Blue in HSV space\n",
    "    elif color==\"blue\":\n",
    "        lower1 = np.array([110, 120, 0])\n",
    "        upper1 = np.array([135, 255, 255])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "\n",
    "    elif color==\"white\":\n",
    "        # sensitivity=45\n",
    "        lower1 = np.array([0,0,175])\n",
    "        upper1 = np.array([255,255,185])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "\n",
    "    elif color==\"black\":\n",
    "        # sensitivity=45\n",
    "        lower1 = np.array([0,0,0])\n",
    "        upper1 = np.array([100,100,200])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "\n",
    "    elif color==\"pink\":\n",
    "        # sensitivity=45\n",
    "        lower1 = np.array([145,110,110])\n",
    "        upper1 = np.array([255,255,255])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "        \n",
    "    elif color==\"brown\":\n",
    "        # sensitivity=45\n",
    "        lower1 = np.array([12,110,110])\n",
    "        upper1 = np.array([18,255,255])\n",
    "        mask = cv2.inRange(image, lower1, upper1) \n",
    "    else:\n",
    "        print(\"Error Color Provided Not Valid\")\n",
    "        assert(False)\n",
    "\n",
    "    #Apply the mask using a bitwise and operator\n",
    "    result = cv2.bitwise_and(result, result, mask=mask)\n",
    "    # cv2_imshow(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638483288082,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "tW0l5RkoPzJI"
   },
   "outputs": [],
   "source": [
    "def get_ball_xy(image,minDist,param1,param2,minRadius,maxRadius):\n",
    "    '''\n",
    "    Code based on: https://stackoverflow.com/questions/60637120/detect-circles-in-opencv\n",
    "\n",
    "    image = input image to detect the circle on\n",
    "    minDist = Minimum distance between the centers of the detected circles. if too large circles may be missed, if too small too many circles may appear.\n",
    "    param1= Method uses canny filter edge detection.  This is the higher threshold of the two passed to the Canny edge detector (the lower one is twice smaller of the larger one).\n",
    "    param2 = accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected.\n",
    "    minRadius = min radius of circle to detect \n",
    "    maxRadius = max radius of circle to detect\n",
    "    '''\n",
    "    #Color Filter tha given image using green\n",
    "    color='brown'\n",
    "    filtered_img= color_filter (image,color)\n",
    "    cv2.imshow(\"\",filtered_img)\n",
    "    #Converting the image into grayscale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Smoothening the Image\n",
    "    blurred = cv2.medianBlur(gray, 25) \n",
    "\n",
    "    #Finds circles in a grayscale image using the Hough transform\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, 1, minDist, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)\n",
    "\n",
    "    #If we detected circles with given params\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        #Loop through them and draw them on the given image + print coordinates\n",
    "        for i in circles[0,:]:\n",
    "            cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "            x_ball=i[0]\n",
    "            y_ball=i[1]\n",
    "            # print(\"x= \",x_ball,\"y= \",y_ball)\n",
    "            cv2.circle(image, (x_ball,y_ball), radius=3, color=(0, 0, 255), thickness=-1)\n",
    "    else:\n",
    "        print(\"Ball Not Found\")\n",
    "        x_ball=-1000\n",
    "        y_ball=-1000\n",
    "    \n",
    "    return x_ball,y_ball\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638483288607,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "AgH4ccbMQCQf"
   },
   "outputs": [],
   "source": [
    "def resize_image(img,percent):\n",
    "    '''\n",
    "    img = input image to be resized\n",
    "    percent = percentage by which to resize the image\n",
    "    '''\n",
    "    # percent of original size\n",
    "    width = int(img.shape[1] * percent / 100)\n",
    "    height = int(img.shape[0] * percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638483288608,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "jNfoos2b2QcP"
   },
   "outputs": [],
   "source": [
    "def align_field(image):\n",
    "    '''Used to align the view of the field into a 2D plane'''\n",
    "\n",
    "    #Performing Colour Filtering to Distinguish the Field\n",
    "    color='green'\n",
    "    result= color_filter (image,color)\n",
    "#     cv2.imshow('',result)\n",
    "#     return 0\n",
    "    # Finding Contours to detect the area of the field\n",
    "    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,28,243,0)\n",
    "    \n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, np.ones((5,5)))\n",
    "    contours,hierarchy = cv2.findContours(closing,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow('contours',closing)\n",
    "    ch = image.copy()\n",
    "    cv2.drawContours(ch,contours,-1,(255,0,0))\n",
    "\n",
    "    \n",
    "    # #Taking the one with the largest area\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    \n",
    "    \n",
    "    # cv2_imshow(result)\n",
    "    # #Taking its Convex hull to get an aproximate rectangle\n",
    "    c=cv2.convexHull(c)\n",
    "    ch = image.copy()\n",
    "    cv2.drawContours(ch,c,-1,(0,255,0))\n",
    "    cv2.imshow('convexHull', thresh)\n",
    "    perimeter = cv2.arcLength(c, True)\n",
    "\n",
    "\n",
    "    #Using an approximate polygon to get the corners of the rectangle\n",
    "    approx= cv2.approxPolyDP(c, 0.05 * perimeter, True)\n",
    "    corners=np.zeros((4,2),dtype=np.int16)\n",
    "    i=0\n",
    "    \n",
    "    if (len(approx)==0):\n",
    "        print(\"Poor color Filtering of field\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    #if the contours detected don't form a rectangle then we approximate them using a minimum rectangle area\n",
    "    if len(approx)>4:\n",
    "#         hull =[]\n",
    "#         for c in contours:\n",
    "#             if cv2.contourArea(c)>10:\n",
    "#                 hull.append(cv2.convexHull(c,False))\n",
    "#         rect = cv2.minAreaRect(np.concatenate(hull,axis=0))\n",
    "#         box = cv2.boxPoints(rect)\n",
    "#         box = np.int0(box)\n",
    "#         cv2.drawContours(result,[box],0,(0,0,255),2)\n",
    "#         c=box\n",
    "#         approx= cv2.approxPolyDP(c, 0.05 * perimeter, True)\n",
    "        return\n",
    "\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #Drawing a circle at every corner of the field and converting the list of corner points to array\n",
    "    for point in approx:\n",
    "        x, y = point[0]\n",
    "        corners[i,0]=x\n",
    "        corners[i,1]=y    \n",
    "        cv2.circle(result, (x, y), 3, (0, 255, 0), -1)\n",
    "        i=i+1\n",
    "        cv2.putText(result,str(i), (x,y), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow('b',result)\n",
    "    \n",
    "\n",
    "    #Calculating the pairwise distance between every corner point\n",
    "    dist=scipy.spatial.distance.pdist(corners,'euclidean')\n",
    "    #Getting rid of the diagonals as they are the two longest distances\n",
    "    edges=np.sort(corners)[:4]\n",
    "#     edges=np.sort(dist)[:4]\n",
    "    #Since the edges array is sorted the two smallest values are the width and the others are length\n",
    "    width = edges[:2]\n",
    "    length = edges[2:]\n",
    "    \n",
    "#     print(width)\n",
    "#     return 0\n",
    "    #Getting Max length and width\n",
    "    # if image.shape[0]>image.shape[1]:\n",
    "    #   maxWidth=max(np.max((width).astype(int)),np.max((length).astype(int)))\n",
    "    #   maxLength=min(np.max((width).astype(int)),np.max((length).astype(int)))\n",
    "    # else:\n",
    "    maxWidth=np.max((width).astype(int))\n",
    "    maxLength=np.max((length).astype(int))\n",
    "\n",
    "    #Converting to float the distorted rectangle\n",
    "    input_pts=np.float32(corners)\n",
    "    #Building a matrix with the ideal rectangle points (i.e. max distances)\n",
    "    output_pts = np.float32([[0, 0],\n",
    "                          [0, maxLength - 1],\n",
    "                          [maxWidth - 1, maxLength - 1],\n",
    "                          [maxWidth - 1, 0]])\n",
    "\n",
    "    # Compute the perspective transform M\n",
    "    M = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "\n",
    "    #Wrapping the image based on the perspective transform\n",
    "    out = cv2.warpPerspective(image,M,(maxWidth, maxLength),flags=cv2.INTER_LINEAR)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1638483289075,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "IvU78q6vOnfT"
   },
   "outputs": [],
   "source": [
    "def detect_box(image,color):\n",
    "    blurred_image = cv2.GaussianBlur(image,(21,21),cv2.BORDER_DEFAULT)\n",
    "    #Color filtering in yellow\n",
    "    result3= color_filter (blurred_image,color)\n",
    "    #--->\n",
    "    plt.imshow(cv2.cvtColor(result3, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    #Contour DEtection\n",
    "    gray = cv2.cvtColor(result3, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,120,243,0)\n",
    "    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #Taking contour with biggest area\n",
    "    cnt= max(contours, key = cv2.contourArea)\n",
    "    if (len(cnt)==0):\n",
    "        print(\"Robot not detected on field\")\n",
    "        return\n",
    "\n",
    "    #Forming a rectangle of min area arround them\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    \n",
    "    #Contour drawing\n",
    "    # cv2.drawContours(resized_image,[box],0,(0,0,255),2)\n",
    "\n",
    "    #Calculating centroid of rectangle using moments\n",
    "    M = cv2.moments(box)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    # cv2.circle(resized_image,(cx,cy),1,(0,255,0),12)\n",
    "\n",
    "    return cx,cy\n",
    "\n",
    "\n",
    "def get_robot_pose (image):\n",
    "\n",
    "    #Detect the yellow box\n",
    "    cx_yellow,cy_yellow=detect_box(image,'yellow')\n",
    "\n",
    "    #Detect the red box\n",
    "    cx_red,cy_red=detect_box(image,'blue')\n",
    "\n",
    "\n",
    "\n",
    "    #Save red box center as robot's xy\n",
    "    robot_xy=(cx_red,cy_red)\n",
    "\n",
    "    #Draw orientation Vector using yellow and red box centroids\n",
    "    cv2.arrowedLine(image,(cx_red,cy_red),(cx_yellow,cy_yellow),(255,0,0),3)\n",
    "\n",
    "    #Draw Point for Centroid of Robot\n",
    "    cv2.circle(image,(cx_red,cy_red),1,(0,255,0),12)\n",
    "\n",
    "    # cv2_imshow(image)\n",
    "\n",
    "    #Calculating the angle of the robot\n",
    "\n",
    "    #First calculating the horizontal and vertical displacements\n",
    "    dy=(cy_yellow-cx_red)\n",
    "    dx=(cx_yellow-cx_red)\n",
    "\n",
    "    #Calculating the angle between the two dx dy\n",
    "    #We return the negative value because the origin of image is on the top left corner but by convention we take it at the bottom\n",
    "    robot_angle=-math.atan2(dx,dy)\n",
    "    return robot_xy,robot_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1638483289705,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "8ef3h_ohc6sQ"
   },
   "outputs": [],
   "source": [
    "def draw_origin(image):\n",
    "    '''\n",
    "    Used to draw the origin on the image's left corner\n",
    "    '''\n",
    "    im_size=np.shape(image)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #Drawing x-axis\n",
    "    cv2.arrowedLine(image, (5, im_size[0]-10), (45, im_size[0]-10), (0,0, 255), thickness=2)\n",
    "    cv2.putText(image, 'x', (45+15, im_size[0]-10), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    #Drawing y-axis\n",
    "    cv2.arrowedLine(image, (5, im_size[0]-10), (5, -35+im_size[0]-10), (0,0, 255), thickness=2)\n",
    "    cv2.putText(image, 'y', (5+15, -35+im_size[0]-10), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_map(image):\n",
    "    blurred_image_red = cv2.GaussianBlur(image,(19,19),cv2.BORDER_DEFAULT)\n",
    "    image_red=color_filter(blurred_image_red,'pink')\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    \n",
    "    map=np.empty_like(image_red)\n",
    "\n",
    "    map[image_red!=0]=0\n",
    "    map[image_red==0]=255\n",
    "    erosion = cv2.erode(map,kernel,iterations = 7)\n",
    "    \n",
    "    print(\"Map\")\n",
    "    plt.imshow(cv2.cvtColor(erosion, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7504,
     "status": "ok",
     "timestamp": 1638483513503,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "jeIwqs0okhqN",
    "outputId": "3a39eecf-6ff3-401e-b856-ec0e5042a5a1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import scipy.spatial.distance\n",
    "import math\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# # orig_image = cv2.imread('/content/drive/MyDrive/images/scene-4.jpeg')\n",
    "# # orig_image = cv2.imread('/content/drive/MyDrive/images/test/opencv_frame_3.png')\n",
    "# orig_image = cv2.imread('./pink_obs3.jpg')\n",
    "# # cv2_imshow(orig_image)\n",
    "# image=resize_image(orig_image,80)\n",
    "\n",
    "# image=align_field(image)\n",
    "\n",
    "# image=cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "# plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "\n",
    "# x_ball,y_ball=get_ball_xy(image, \n",
    "#             minDist = 550,\n",
    "#             param1 = 30, \n",
    "#             param2 = 19, \n",
    "#             minRadius = 20,\n",
    "#             maxRadius = 55)\n",
    "\n",
    "# map = generate_map(image)\n",
    "# draw_origin(image)\n",
    "# robot_xy,robot_angle=get_robot_pose(image)\n",
    "\n",
    "\n",
    "# print(\"Ball_XY: \",x_ball,y_ball)\n",
    "# print(\"Robot_XY: \",robot_xy[0],robot_xy[1])\n",
    "# print(\"Robot_theta: \",math.degrees(robot_angle))\n",
    "\n",
    "\n",
    "# plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(3)\n",
    "\n",
    "# # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# # out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret==True:\n",
    "# #         frame = cv2.flip(frame,0)\n",
    "\n",
    "#         image=resize_image(frame,80)\n",
    "# #         image=align_field(image)\n",
    "# #         out.write(frame)\n",
    "\n",
    "#         cv2.imshow('frame',image)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "# cap.release()\n",
    "\n",
    "# # out.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1638483249657,
     "user": {
      "displayName": "Georgios Apostolides",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16419017087845261316"
     },
     "user_tz": -60
    },
    "id": "8ptW7G7vQcBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-efcc551331f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#         image=cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         image=cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f8c11c8fd4dc>\u001b[0m in \u001b[0;36malign_field\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# #Taking the one with the largest area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "i=0\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    i=i+1\n",
    "    if i<50:\n",
    "        continue\n",
    "    if ret==True:\n",
    "#         frame = cv2.flip(frame,0)\n",
    "        \n",
    "        image=resize_image(frame,90)\n",
    "        \n",
    "        image=align_field(frame)\n",
    "#         image=cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "#         image=cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "#        x_ball,y_ball=get_ball_xy(image, \n",
    "#                                  minDist = 750,\n",
    "#                                  param1 = 12, \n",
    "#                                  param2 = 18, \n",
    "#                                  minRadius = 20,\n",
    "#                                  maxRadius = 35)\n",
    "        \n",
    "\n",
    "        \n",
    "       \n",
    "#         robot_xy,robot_angle=get_robot_pose(image)\n",
    "\n",
    "#         draw_origin(image)\n",
    "#         print(\"Ball_XY: \",x_ball,y_ball)\n",
    "#         print(\"Robot_XY: \",robot_xy[0],robot_xy[1])\n",
    "#         print(\"Robot_theta: \",math.degrees(robot_angle))\n",
    "        \n",
    "        \n",
    "#         out.write(frame)\n",
    "        if (i%30==0):\n",
    "            cv2.imshow('f',image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "#reopening of cap\n",
    "i=0\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        image=resize_image(frame,90)\n",
    "        x_ball,y_ball=get_ball_xy(image, \n",
    "                                      minDist = 750,\n",
    "                                      param1 = 12, \n",
    "                                      param2 = 20, \n",
    "                                      minRadius = 20,\n",
    "                                      maxRadius = 30)\n",
    "    #         out.write(frame)\n",
    "        if (i%30==0):\n",
    "            cv2.imshow('f',image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "# out.release()qq\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNm3A4z5YFgntiLEv935iV",
   "collapsed_sections": [],
   "mount_file_id": "1gR4aLtlnQLZffjWDITvSIceyzUj4fFZu",
   "name": "image_processing_mob_rob",
   "provenance": [
    {
     "file_id": "1OiWNkUsOhGKKD0HkiAK5XdAmmlu7ynM0",
     "timestamp": 1638313435455
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
