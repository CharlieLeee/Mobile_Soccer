{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer Mobile\n",
    "<!-- Introduction of the project -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students: Chengkun Li, Jiangfan Li, Georgios Apostolides, Lucas Represa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project the goal is to combine vision, path planning, local navigation, and filtering in order to make Thymio robot navigate trough a map towards a goal.  \n",
    "\n",
    "As the constraints are established we were free to chose our own implementation. To begin with, a camera is used in order to provide the vision information. The vision module works along with the global path and filter modules extracting estimating and computing the necessary map information, including the robot pose, robot pose, map, static obstacles, and the goal position. \n",
    "\n",
    "Indeed, a Kalman filter performs the estimations of the robot pose. Afterwards, the A* algorithm computes the optimal path. Following this, a global controller gives instructions to the motors for them to follow the optimal path. Finally, a local navigation module is implemented in order to provide a vision-free information to Thymio for the most spontaneous events such as a dynamic obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thymio Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create our soccer field environnement we printed an A1 sheet with the corresponding field. Corners are represented by [...]. A camera performs the vision part by transferring frames to the vision module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision import *\n",
    "vp = VisionProcessor()\n",
    "#vp.open()\n",
    "#img = vp._getImage()\n",
    "img = cv2.imread(\"img/example.jpg\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'green'\n",
    "green_mask = VisionProcessor.color_filter(img, color=color)\n",
    "plt.imshow(cv2.cvtColor(green_mask, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Using Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. find the biggest green part\n",
    "\n",
    "gray = cv2.cvtColor(green_mask, cv2.COLOR_BGR2GRAY)\n",
    "(T, thresh) = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "# morphology operation against noise\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, np.ones((10, 10)))\n",
    "# extract contours\n",
    "_,contours,hierarchy = cv2.findContours(closing,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Taking the one with the largest area # serve as the opening operation to some extent\n",
    "c = max(contours, key = cv2.contourArea)\n",
    "# use a convexHull against noise\n",
    "hull = cv2.convexHull(c)\n",
    "hull_img = np.zeros_like(img)     \n",
    "length = len(hull)\n",
    "for i in range(len(hull)):\n",
    "    cv2.line(hull_img, tuple(hull[i][0]), tuple(hull[(i+1)%length][0]), (255,0,0), 2)\n",
    "hull_img = cv2.cvtColor(hull_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(hull_img)    \n",
    "_,convexcontour,_ = cv2.findContours(hull_img,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "ch = img.copy()\n",
    "cv2.drawContours(ch,convexcontour,-1,(255,0,0),1)\n",
    "#plt.imshow(cv2.cvtColor(ch, cv2.COLOR_RGB2BGR))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. get 4 corners\n",
    "lines = VisionProcessor.divide4(np.array(hull))\n",
    "ll = lines[np.argmax([abs(l[-1]) for l in lines])]\n",
    "lines.remove(ll)\n",
    "rl = lines[np.argmax([abs(l[-1]) for l in lines])]\n",
    "lines.remove(rl)\n",
    "ul = lines[0]\n",
    "dl = lines[1]\n",
    "corners = []\n",
    "i = 1\n",
    "ch = img.copy()\n",
    "for h in [ul, dl]:\n",
    "    for v in [ll, rl]:\n",
    "        x, y = VisionProcessor.intersection(h[0], h[1], -h[2], v[0], v[1], -v[2])\n",
    "        corners.append([x, y])\n",
    "        print(\"corner\",x, y)\n",
    "        cv2.circle(ch, (x, y), 3, (0, 255, 0), -1)\n",
    "        cv2.putText(ch,str(i), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        i += 1\n",
    "        \n",
    "corners = np.array(corners)\n",
    "\n",
    "plt.imshow(ch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Using aruco\n",
    "\n",
    "In this part we get the pixel coordinates of all four corners by using the aruco markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision import *\n",
    "vision_processor = VisionProcessor()\n",
    "img = cv2.imread(\"img/test.jpg\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners, a_image = vision_processor.visualize_aruco(img)\n",
    "corners\n",
    "plt.imshow(cv2.cvtColor(a_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective Projection\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = VisionProcessor.align_field(corners)\n",
    "wraped = VisionProcessor.warp(img, M)\n",
    "plt.imshow(cv2.cvtColor(wraped, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(3)\n",
    "\n",
    "# # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# # out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret==True:\n",
    "# #         frame = cv2.flip(frame,0)\n",
    "\n",
    "#         image=resize_image(frame,80)\n",
    "# #         image=align_field(image)\n",
    "# #         out.write(frame)\n",
    "\n",
    "#         cv2.imshow('frame',image)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "# cap.release()\n",
    "\n",
    "# # out.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ball Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMap = vp.getMap(wraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gMap.scale)\n",
    "print(Thymio_Size/gMap.scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thymio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thymip_state_camera = vp._getThymio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Global Navigation\n",
    "This module aims to plan a path from the start to the goal.\n",
    "The result will be represented in form of a list of Waypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a fake map\n",
    "# h, w = 40, 30\n",
    "pStart = Pos(0,0)\n",
    "pBall = Pos(gMap.height-1,gMap.width-1)\n",
    "# rmap = GridMap(h, w, 0.01)\n",
    "gMap.set_start(pStart)\n",
    "# obslist = [Pos(random.randint(10,h-11),random.randint(10,w-11)) for _ in range(3)]\n",
    "# rmap.set_obs(obslist)\n",
    "\n",
    "\n",
    "# obsmap = [[int(val) for val in li] for li in rmap.obs_map]\n",
    "# obsmap[pStart.x][pStart.y] = 0.3\n",
    "# obsmap[pBall.x][pBall.y] = 0.7\n",
    "###\n",
    "obsmap = gMap.obs_map\n",
    "plt.imshow(obsmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "#### Enlarge the obstacles\n",
    "After getting the environment map, we need to enlarge the obstacles to make sure every point is safe for thymio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_navigation import *\n",
    "planner =  PathPlanner(gMap, path_simplification=False)\n",
    "plt.imshow(planner.obs) # has auto enlarged the obs when load the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMap.check(Pos(600, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caculate the actual position\n",
    "The goal position represent where that the head of thmio will reach; We need to calculate the actual center position of thymio for the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pGoal1 = planner.approach(pBall)\n",
    "planner.set_goal(pGoal1)\n",
    "print(\"Goal State:\",pGoal1)\n",
    "import copy\n",
    "obs = copy.deepcopy(planner.obs)\n",
    "obs[pStart.x][pStart.y] = 0.3\n",
    "obs[pBall.x][pBall.y] = 0.7\n",
    "obs[pGoal1.pos.x][pGoal1.pos.y] = 0.5\n",
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Planning\n",
    "We implemented two ways of path planning, namely, A* and RRT.\n",
    "A* is an optimal path planning algorithm.\n",
    "RRT is usually applied for high-dimension path planning. For our project, if we get a quite large grid map, the computational cost will be high, and RRT can boost up the speed. We should note that, it's not a optimal algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of A*\n",
    "# points in the same direction have been deleted\n",
    "planner.method = \"A*\"\n",
    "planner.neighbor = 8\n",
    "apath = planner.plan()\n",
    "nobs = copy.deepcopy(obs)\n",
    "for p in apath:\n",
    "    nobs[p.x][p.y] = 0.9\n",
    "plt.imshow(nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of RRT\n",
    "planner.method = \"RRT\"\n",
    "rrtpath = planner.plan()\n",
    "nobs = copy.deepcopy(obs)\n",
    "for p in rrtpath:\n",
    "    nobs[p.x][p.y] = 0.9\n",
    "plt.imshow(nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "#### Collect waypoints in same direction\n",
    "The waypoints in same direction just have the same effect for path tracking, so we try to elimate some redandent points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apath = planner.collect_wps(apath)\n",
    "nobs = copy.deepcopy(obs)\n",
    "for p in apath:\n",
    "    nobs[p.x][p.y] = 0.9\n",
    "plt.imshow(nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shrink the waypoints\n",
    "Try to connect the grandparent to grandchild directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apath = planner.path_simplification(apath)\n",
    "nobs = copy.deepcopy(obs)\n",
    "for p in apath:\n",
    "    nobs[p.x][p.y] = 0.9\n",
    "plt.imshow(nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_path = planner.assign_ori(apath)\n",
    "for s in Global_path:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Navigation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local navigation module allows to take advantage of the proximity sensors located on the five front horizontal proximity sensors. The objective is to bypass the unknown local obstacle for further re-computing of the controller to correct Thymio's speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Input**\n",
    "\n",
    "    - Horizontal proximity sensor values\n",
    "\n",
    "\n",
    "- **Output**\n",
    "\n",
    "    - Motion control command for robot translation and rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "| Name                | Meaning                                                      | Type (Unit) | Global |\n",
    "| :------------------- | :------------------------------------------------------------ | :----------- | :------ |\n",
    "| `max_speed`        |  Nominal speed                 | Int         |  |\n",
    "| `obstThrL`      | Low obstacle threshold to switch state 1->0                | Int         |    |\n",
    "| `obstThrH` | High obstacle threshold to switch state 0->1                    | Int         |   |\n",
    "| `obstSpeedGain`         | Variation of speed according to the distance of obstacle | Int |   |\n",
    "| `state`         | 0=global navigation, 1=local navigation | Bool |   |\n",
    "| `obst`         | Measurements from left and right prox sensors | Int |   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "Two functions are basically doing the local avoidance. obs is meant to detect an obstacle and return the new state of the robot as stated in the parameters tabular. obstacle_avoidance updates the new speed to return to thymio. It will return the inputs to the motors function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 100       # nominal speed\n",
    "speedGain = 2      # gain used with ground gradient\n",
    "obstThrL = 10      # low obstacle threshold to switch state 1->0\n",
    "obstThrH = 20      # high obstacle threshold to switch state 0->1\n",
    "obstSpeedGain = 5  # /100 (actual gain: 5/100=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tdmclient.notebook.sync_var\n",
    "def motors(left, right):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left\n",
    "    motor_right_target = right\n",
    "    \n",
    "@tdmclient.notebook.sync_var   \n",
    "def encoders():\n",
    "    global motor_left_speed, motor_right_speed\n",
    "    speed = []\n",
    "    while len(speed) < 2 :\n",
    "        speed = [motor_left_speed, motor_right_speed]\n",
    "    return speed\n",
    "    \n",
    "@tdmclient.notebook.sync_var\n",
    "def obstacle_avoidance():\n",
    "    global prox_horizontal, state, obst, obstSpeedGain, speed0, speedGain \n",
    "    obst = [prox_horizontal[0], prox_horizontal[4]]\n",
    "    \n",
    "    state = 0\n",
    "    if (obst[0] > obstThrH):\n",
    "        state = 1\n",
    "    elif (obst[1] > obstThrH):\n",
    "        state = 1\n",
    "        \n",
    "    if state == 1:\n",
    "        left_speed = max_speed // 2 + obstSpeedGain * (obst[0] // 100)\n",
    "        right_speed = max_speed // 2 + obstSpeedGain * (obst[1] // 100)\n",
    "        motors(left_speed, right_speed)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering\n",
    "### Overview\n",
    "The goal of the filtering module is to integrate (if available) the measurements (in our case, the vision output) with the information from the motor encoders to estimate a reasonable state for Thymio. To this end, we use Extended Kalman Filter (EKF) technique in our project. Compared to the regular Kalman Filter, Extended Kalman Filter is the nonlinear version of the Kalman filter which utilizes first (or second) order derivative to do the approximation.\n",
    "\n",
    "## Robot States\n",
    "\n",
    "The state of Thymio is represented as $$\\mu_t = [x_t, y_t, \\theta_t]^T$$ as shown in the figure below, corresponding to the x, y, and orientation of the robot as shown in the figure below.\n",
    "<center><img src=\"Notebook_figures/robot_state.png\" alt=\"\" style=\"width: 800px;\"/></center>\n",
    "Where we denote the displacement in distance as D and displacement in orientation as T (for the sake of simplicity we omit the indices).\n",
    "\n",
    "## State Space Representation of EKF\n",
    "### Action and Measurement Model\n",
    "The action and measurement model of EKF is shown below, where $f$ and $h$ are two nonlinear functions.\n",
    "\\begin{array}{l}\\boldsymbol{x}_{t}=f\\left(\\boldsymbol{x}_{t-1}, \\boldsymbol{u}_{t}\\right)+\\boldsymbol{w}_{t} \\\\\\boldsymbol{z}_{t}=h\\left(\\boldsymbol{x}_{t}\\right)+\\boldsymbol{v}_{t}\\end{array}\n",
    "\n",
    "The prediction stage of EKF is described as:\n",
    "$$\\hat{\\boldsymbol{x}}_{t \\mid t-1}=f\\left(\\hat{\\boldsymbol{x}}_{t-1 \\mid t-1}, \\boldsymbol{u}_{t}\\right)$$\n",
    "\n",
    "\n",
    "where the input of the system is a vector consisting of two encoder displacements of Thymio left/right wheels represented as $u_t = [\\Delta S_r,\\Delta S_l ]^T$\n",
    "<center><img src=\"Notebook_figures/turning.png\" alt=\"\" style=\"width: 300px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filtering\n",
    "# Motor Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_state = np.array([0.0, 0.0, 0]).reshape(-1, 1) # initial state\n",
    "pre_cov = np.ones([3, 3]) * 0.03 # initial covariance\n",
    "G_filter = filtering.KF(pre_state, pre_cov, qx=0.1, qy=0.1, qtheta=0.3, rl=0.1, rr=0.1, b=0.0927)\n",
    "G_filter.timer = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_filter.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_state = np.array([0.0, 0.0, 0]).reshape(-1, 1) # initial state\n",
    "pre_cov = np.ones([3, 3]) * 0.03 # initial covariance\n",
    "G_filter = filtering.KF(pre_state, pre_cov, qx=0.1, qy=0.1, qtheta=0.3, rl=0.1, rr=0.1, b=0.0927)\n",
    "G_filter.timer = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_verbose = True\n",
    "S_camera_interval = 1000 #ms\n",
    "S_motion_interval = 200 #ms\n",
    "S_track_interval = 0.2 #s\n",
    "\n",
    "S_epsilon_dis = 0.005\n",
    "S_epsilon_theta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionController_JN:\n",
    "    def __init__(self, time_interval = 10, # s \n",
    "                 eps_delta_r = 0.005, eps_delta_theta = 0.1,\n",
    "                 max_speed = 100, \n",
    "                 speed_scale = 0.000315, # (m/s) / speed_in_motor_command; 0.000315 for speed<200; 0.0003 for speed \\in (200,400)\n",
    "                 rotate_scale = 0.05, # TODO (rad/s) / speed_in_motor_command\n",
    "                 obstSpeedGain = 5,  # /100 (actual gain: 5/100=0.05)\n",
    "                 verbose = False\n",
    "                 ):\n",
    "        \"\"\"Motion Controller\n",
    "\n",
    "        Connected with thymio interface\n",
    "        Interface between high-level command and Thymio motion\n",
    "        \"\"\"\n",
    "        self.interval = time_interval   # s, control frequency\n",
    "        self.timer = time.time()\n",
    "        self.displacement = [0, 0]\n",
    "        self.speed = [0, 0]\n",
    "        \n",
    "        self.eps_delta_r = eps_delta_r\n",
    "        self.eps_delta_theta = eps_delta_theta\n",
    "\n",
    "        self.max_speed = max_speed\n",
    "        self.speed_scale = speed_scale\n",
    "        self.rotate_scale = rotate_scale\n",
    "        self.obstSpeedGain = obstSpeedGain\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # -- Local Navigation --\n",
    "    def avoid(self):\n",
    "        return obstacle_avoidance()\n",
    "\n",
    "    # -- Path Tracking --        \n",
    "    def path_tracking(self, waypoint, Thymio_state, theta_track = False):\n",
    "        \"\"\"Follow the path\n",
    "\n",
    "        @return: waypoint reached\n",
    "        \"\"\"\n",
    "        # 4 Track the waypoints\n",
    "        # 4.1 Are we close enough to the next waypoint?  \n",
    "        delta_r = Thymio_state.dis(waypoint)\n",
    "        if delta_r < self.eps_delta_r:\n",
    "            if self.verbose:\n",
    "                print(\"Close to the point\")\n",
    "            # check the rotation\n",
    "            delta_theta = Thymio_state.delta_theta(waypoint)\n",
    "            if not theta_track or abs(delta_theta) < self.eps_delta_theta:\n",
    "                if self.verbose:\n",
    "                    print(Thymio_state,\"Point Finished\")\n",
    "                return True\n",
    "            else:\n",
    "                self.rotate(delta_theta) #PULSE\n",
    "        else:\n",
    "            # 4.2 Go to the next waypoint\n",
    "            headto_theta = Thymio_state.headto(waypoint)\n",
    "            delta_theta = headto_theta - Thymio_state.ori\n",
    "            delta_theta = Pos.projectin2pi(delta_theta)\n",
    "            if self.verbose:\n",
    "                print(F\"headto_theta: {headto_theta}\")\n",
    "            if abs(delta_theta) > self.eps_delta_theta:#1.0:\n",
    "                self.rotate(delta_theta)\n",
    "            # elif abs(delta_theta) > self.eps_delta_theta:\n",
    "            #     self.approach(delta_r, delta_theta)\n",
    "            else:\n",
    "                self.approach(delta_r, 0)\n",
    "            return False\n",
    "\n",
    "    # -- Movement --\n",
    "    def approach(self, delta_r, delta_theta = 0):\n",
    "        \"\"\"approach to the goal point\n",
    "        \n",
    "            move with modification of direction\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(F\"approach to dr:{delta_r}, dt:{delta_theta}\")\n",
    "        # assume u only move <interval> s. \n",
    "        advance_speed = min(delta_r/self.interval/self.speed_scale * 20 + 20, self.max_speed)\n",
    "        delta_speed = delta_theta/self.interval/self.rotate_scale\n",
    "        if delta_speed > 0:\n",
    "            delta_speed = min(delta_speed, self.max_speed/2)\n",
    "            self.move(min(advance_speed, self.max_speed - 2*abs(delta_speed)), delta_speed)\n",
    "        else:\n",
    "            delta_speed = max(delta_speed, -self.max_speed/2)\n",
    "            self.move(min(advance_speed, self.max_speed - 2*abs(delta_speed)), delta_speed)\n",
    "\n",
    "    def rotate(self, delta_theta):\n",
    "        \"\"\"rotate in place\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(F\"rotate to dt:{delta_theta}\")\n",
    "        delta_speed = delta_theta/(self.interval)/self.rotate_scale\n",
    "        if delta_speed > 0:\n",
    "            self.move(0, min(delta_speed + 10, self.max_speed))\n",
    "        else:\n",
    "            self.move(0, max(delta_speed - 10, -self.max_speed))\n",
    "\n",
    "    def move(self, vel, omega = 0):\n",
    "        \"\"\"\n",
    "        move with transitional velocity and rotational velocity\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(F\"move with {vel}, {omega}\")\n",
    "        self._set_motor(vel - omega, vel + omega)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop both motors\n",
    "        \"\"\"\n",
    "        self._set_motor(0, 0)\n",
    "\n",
    "    def update_displacement(self):\n",
    "        starter = time.time()\n",
    "        interval = starter - self.timer\n",
    "        self.timer = starter\n",
    "        rls, rrs = encoders()\n",
    "        # rls = int(rls * float(os.getenv(\"OFFSET_WHEELS\")))\n",
    "        #rls = rls if rls < 2 ** 15 else rls - 2 ** 16\n",
    "        #rrs = rrs if rrs < 2 ** 15 else rrs - 2 ** 16\n",
    "        rls = 0 if abs(rls) > self.max_speed * 1.1 else rls\n",
    "        rrs = 0 if abs(rrs) > self.max_speed * 1.1 else rrs \n",
    "        self.displacement[0] += rls*interval*self.speed_scale\n",
    "        self.displacement[1] += rrs*interval*self.speed_scale\n",
    "\n",
    "    def _set_motor(self, ls, rs):\n",
    "        ls = (int)(ls)\n",
    "        rs = (int)(rs)\n",
    "        # l_speed = int(ls / float(os.getenv(\"OFFSET_WHEELS\")))\n",
    "        #l_speed = ls if ls >= 0 else 2 ** 16 + ls\n",
    "        #r_speed = rs if rs >= 0 else 2 ** 16 + rs           \n",
    "        self.update_displacement()\n",
    "        motors(ls, rs)\n",
    "\n",
    "    def get_displacement(self):\n",
    "        self.update_displacement()\n",
    "        ret = self.displacement\n",
    "        self.displacement = [0, 0]\n",
    "        # if self.verbose:\n",
    "        #     print(F\"Displacement:{ret}\")\n",
    "        return ret\n",
    "\n",
    "    \n",
    "G_mc = MotionController_JN(verbose = G_verbose, time_interval = S_motion_interval/1000.0 )\n",
    "print(S_motion_interval)\n",
    "print(G_mc.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this main all the motion control and local avoidance functions are called in a while loop. This merges all the modules and communicates with the thymio thanks to the motion contol module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_track_timer = time.time()\n",
    "G_mc.get_displacement()\n",
    "\n",
    "def localizate():\n",
    "    \"\"\"Track Where Thymio is\"\"\"\n",
    "    global G_camera_timer\n",
    "    starter = G_filter.timer\n",
    "    # 3. Localization \n",
    "    # 3.1 odometer\n",
    "    dsl, dsr = G_mc.get_displacement()\n",
    "    # 3.2 With Vision\n",
    "        # if starter - G_camera_timer > S_camera_interval:\n",
    "        #     vision_thymio_state = G_vision._getThymio()\n",
    "        #     # Vision Failed\n",
    "        #     if vision_thymio_state is None:\n",
    "        #         G_filter.kalman_filter(dsr, dsl)\n",
    "        #     else:\n",
    "        #         G_camera_timer = starter\n",
    "        #         G_filter.kalman_filter(dsr, dsl, vision_thymio_state)\n",
    "        # else:        \n",
    "        #     G_filter.kalman_filter(dsr, dsl)\n",
    "    G_filter.kalman_filter(dsr, dsl)\n",
    "    G_filter.plot_gaussian()\n",
    "    thymio_state = G_filter.get_state()\n",
    "    return thymio_state\n",
    "\n",
    "print(localizate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    G_filter.states = [np.array([0.0, 0.0, 0]).reshape(-1, 1)] # initial state\n",
    "    G_filter.covs = [np.ones([3, 3]) * 0.03]    \n",
    "    G_track_timer = time.time()\n",
    "    G_mc.get_displacement()\n",
    "    print(localizate())\n",
    "   \n",
    "reset() \n",
    "## Fake Waypoints\n",
    "Global_path = [State(Pos(0.1,0.0),0), State(Pos(0.1, 0.1),0.0),State(Pos(0.15, 0.15),0.0), State(Pos(0.2,0.2),0)]\n",
    "Goal_state = Global_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_timer = 0.0\n",
    "while True:\n",
    "    starter = time.time()\n",
    "    # 3. Localization\n",
    "    Thymio_state = localizate()\n",
    "    # 2.2.1 Finished?\n",
    "    if Thymio_state.dis(Goal_state) < S_epsilon_dis \\\n",
    "        and abs(Thymio_state.ori - Goal_state.ori) < S_epsilon_theta:\n",
    "        G_mc.stop()\n",
    "        if G_verbose:\n",
    "            print(\"Terminate Reached!\")\n",
    "        break\n",
    "    # 2.2.2 Is there obstacles on the front?\n",
    "    obs_front = G_mc.avoid() # do local navigation for, like, 10ms\n",
    "    #     # TODO: replan\n",
    "    if (not obs_front) and starter - G_track_timer > S_track_interval:\n",
    "        # 4. Follow the path    # <-- The only task can run under low frequency\n",
    "        reached = G_mc.path_tracking(Global_path[0], Thymio_state, len(Global_path) == 1)\n",
    "        if reached:\n",
    "            print(Global_path[0],\"reached\")\n",
    "            Global_path = Global_path[1:]\n",
    "            # assume Global_path is not empty because of 2.2.1\n",
    "        G_track_timer = starter\n",
    "    #loop_time = time.time() - starter\n",
    "    time.sleep(0.15)\n",
    "    if starter - debug_timer > S_track_interval:\n",
    "        debug_timer = starter\n",
    "        print(F\"thymio: {Thymio_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motors(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b10cf93940e5c0473413f3fc99b95e2c1997f6e8852312471085cb7234ec8d25"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
